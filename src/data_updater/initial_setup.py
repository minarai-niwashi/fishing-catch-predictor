#!/usr/bin/env python3
"""
fishing_data.csvåˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

data-daily-scraiping-chokaãƒã‚±ãƒƒãƒˆã‹ã‚‰å…¨å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€
fishing-catch-predictorãƒã‚±ãƒƒãƒˆã«åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹

æ³¨æ„: åˆå›ã®ã¿å®Ÿè¡Œã€‚å…¨æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã€ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã¾ã™ã€‚
"""

import io
import json
import os
import re
from datetime import datetime
from typing import List, Optional

import boto3
import pandas as pd

# ç’°å¢ƒå¤‰æ•°
SOURCE_BUCKET = os.environ.get('SOURCE_BUCKET', 'data-daily-scraiping-choka')
DEST_BUCKET = os.environ.get('DEST_BUCKET', 'fishing-catch-predictor')
FACILITY = os.environ.get('FACILITY', 'honmoku')
AWS_REGION = os.environ.get('AWS_REGION', 'ap-northeast-1')


def list_all_date_folders(s3_client, bucket: str, facility: str) -> List[str]:
    """
    S3ã‹ã‚‰å…¨ã¦ã®æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒªã‚¹ãƒˆ

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        facility: æ–½è¨­å

    Returns:
        List[str]: æ—¥ä»˜æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆï¼ˆYYYY-MM-DDï¼‰
    """
    prefix = f"data/{facility}/"
    paginator = s3_client.get_paginator('list_objects_v2')

    date_folders = set()
    for page in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter='/'):
        if 'CommonPrefixes' in page:
            for obj in page['CommonPrefixes']:
                folder_path = obj['Prefix']
                # data/honmoku/YYYY-MM-DD/ ã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
                date_str = folder_path.rstrip('/').split('/')[-1]
                # YYYY-MM-DDå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
                if re.match(r'^\d{4}-\d{2}-\d{2}$', date_str):
                    date_folders.add(date_str)

    return sorted(list(date_folders))


def parse_daily_data(
    s3_client,
    bucket: str,
    facility: str,
    date_str: str
) -> Optional[dict]:
    """
    æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ‘ãƒ¼ã‚¹

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        facility: æ–½è¨­å
        date_str: æ—¥ä»˜æ–‡å­—åˆ—ï¼ˆYYYY-MM-DDï¼‰

    Returns:
        dict: ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆdate, aji_count, visitors, water_temp, weatherï¼‰
              ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯None
    """
    base_prefix = f"data/{facility}/{date_str}"

    try:
        # head.csvã‚’èª­ã¿è¾¼ã¿
        head_key = f"{base_prefix}/head.csv"
        head_response = s3_client.get_object(Bucket=bucket, Key=head_key)
        head_df = pd.read_csv(io.BytesIO(head_response['Body'].read()))

        if len(head_df) == 0:
            return None

        # å¤©æ°—ãƒ»æ°´æ¸©ãƒ»æ¥å ´è€…æ•°ã‚’å–å¾—
        row = head_df.iloc[0]
        weather = row.get('å¤©æ°—', None)
        water_temp_str = row.get('æ°´æ¸©', None)
        visitors_str = row.get('æ¥å ´è€…æ•°') if 'æ¥å ´è€…æ•°' in row.index else row.get('å…¥å ´è€…æ•°', None)

        # æ°´æ¸©ã‚’ãƒ‘ãƒ¼ã‚¹
        water_temp = None
        if pd.notna(water_temp_str):
            match = re.search(r'([\d.]+)', str(water_temp_str))
            if match:
                water_temp = float(match.group(1))

        # æ¥å ´è€…æ•°ã‚’ãƒ‘ãƒ¼ã‚¹
        visitors = None
        if pd.notna(visitors_str):
            match = re.search(r'(\d+)', str(visitors_str))
            if match:
                visitors = int(match.group(1))

        # body.csvã‚’èª­ã¿è¾¼ã¿
        body_key = f"{base_prefix}/body.csv"
        body_response = s3_client.get_object(Bucket=bucket, Key=body_key)
        body_df = pd.read_csv(io.BytesIO(body_response['Body'].read()))

        # ã‚¢ã‚¸ã®åˆè¨ˆã‚’å–å¾—
        aji_count = 0
        for _, fish_row in body_df.iterrows():
            fish_name = fish_row.get('é­š', None)
            if fish_name == 'ã‚¢ã‚¸':
                count_str = fish_row.get('åˆè¨ˆ', None)
                if pd.notna(count_str):
                    try:
                        aji_count = int(count_str)
                    except ValueError:
                        match = re.search(r'(\d+)', str(count_str))
                        if match:
                            aji_count = int(match.group(1))
                break

        date_obj = datetime.strptime(date_str, '%Y-%m-%d')

        return {
            'date': date_obj,
            'aji_count': aji_count,
            'visitors': visitors,
            'water_temp': water_temp,
            'weather': weather
        }

    except Exception as e:
        print(f"  âš  {date_str}: ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def create_initial_fishing_data(
    s3_client,
    source_bucket: str,
    dest_bucket: str,
    facility: str
) -> pd.DataFrame:
    """
    å…¨å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰fishing_data.csvã‚’åˆæœŸç”Ÿæˆ

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        source_bucket: ã‚½ãƒ¼ã‚¹ãƒã‚±ãƒƒãƒˆ
        dest_bucket: ä¿å­˜å…ˆãƒã‚±ãƒƒãƒˆ
        facility: æ–½è¨­å

    Returns:
        DataFrame: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    print("ğŸ“‚ æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ä¸­...")
    date_folders = list_all_date_folders(s3_client, source_bucket, facility)
    print(f"âœ“ {len(date_folders)}å€‹ã®æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç™ºè¦‹")

    if len(date_folders) == 0:
        raise RuntimeError("æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    print(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {date_folders[0]} ã€œ {date_folders[-1]}")
    print(f"\nâš  è­¦å‘Š: {len(date_folders) * 3}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼ˆã‚³ã‚¹ãƒˆã«æ³¨æ„ï¼‰")
    print("å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (Ctrl+Cã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«)")

    # ãƒ‡ãƒ¼ã‚¿åé›†
    all_data = []
    success_count = 0
    error_count = 0

    for i, date_str in enumerate(date_folders, 1):
        if i % 10 == 0 or i == len(date_folders):
            print(f"  é€²æ—: {i}/{len(date_folders)} ({i/len(date_folders)*100:.1f}%)")

        data_entry = parse_daily_data(s3_client, source_bucket, facility, date_str)

        if data_entry is not None:
            all_data.append(data_entry)
            success_count += 1
        else:
            error_count += 1

    # DataFrameã‚’ä½œæˆ
    df = pd.DataFrame(all_data)
    df = df.sort_values('date').reset_index(drop=True)

    print(f"\nâœ“ ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
    print(f"  æˆåŠŸ: {success_count}æ—¥")
    print(f"  ã‚¨ãƒ©ãƒ¼: {error_count}æ—¥")
    print(f"  åˆè¨ˆ: {len(df)}è¡Œ")

    return df


def lambda_handler(event, context):
    """
    Lambdaé–¢æ•°ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç”¨ï¼‰

    æ³¨æ„: ã“ã®Lambdaé–¢æ•°ã¯åˆå›ã®ã¿å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
          å…¨å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã€ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã¾ã™ã€‚

    Args:
        event: Lambda ã‚¤ãƒ™ãƒ³ãƒˆ
        context: Lambda ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        dict: ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    """
    try:
        print("=" * 80)
        print("fishing_data.csv åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
        print("=" * 80)
        print("\nâš  è­¦å‘Š: å…¨å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰\n")

        # S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        s3_client = boto3.client('s3', region_name=AWS_REGION)

        # åˆæœŸãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        df = create_initial_fishing_data(
            s3_client=s3_client,
            source_bucket=SOURCE_BUCKET,
            dest_bucket=DEST_BUCKET,
            facility=FACILITY
        )

        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼:")
        print(f"  ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {df['date'].min().date()} ã€œ {df['date'].max().date()}")
        print(f"  ç·æ—¥æ•°: {len(df)}æ—¥")
        print(f"\n  æ¬ æå€¤:")
        print(df.isnull().sum().to_string())

        # S3ã«ä¿å­˜
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False)

        dest_key = 'data/fishing_data.csv'
        s3_client.put_object(
            Bucket=DEST_BUCKET,
            Key=dest_key,
            Body=csv_buffer.getvalue()
        )

        print(f"\nâœ“ S3ã«ä¿å­˜: s3://{DEST_BUCKET}/{dest_key}")
        print("\n" + "=" * 80)
        print("âœ… åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
        print("=" * 80)

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†',
                'total_rows': len(df),
                'date_range': {
                    'start': df['date'].min().strftime('%Y-%m-%d'),
                    'end': df['date'].max().strftime('%Y-%m-%d')
                }
            }, ensure_ascii=False, indent=2)
        }

    except Exception as e:
        error_message = f"åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        print(f"ERROR: {error_message}")

        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': error_message
            }, ensure_ascii=False, indent=2)
        }


# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨
if __name__ == '__main__':
    response = lambda_handler({}, {})
    print(json.dumps(json.loads(response['body']), ensure_ascii=False, indent=2))
