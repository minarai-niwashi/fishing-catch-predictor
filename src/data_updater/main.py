#!/usr/bin/env python3
"""
fishing_data.csvæ›´æ–°Lambdaé–¢æ•°

data-daily-scraiping-chokaãƒã‚±ãƒƒãƒˆã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€
fishing-catch-predictorãƒã‚±ãƒƒãƒˆã®fishing_data.csvã‚’å¢—åˆ†æ›´æ–°ã™ã‚‹
"""

import io
import json
import os
import re
from datetime import datetime, timedelta
from typing import Optional, Tuple

import boto3
import pandas as pd


# ç’°å¢ƒå¤‰æ•°
SOURCE_BUCKET = os.environ.get('SOURCE_BUCKET', 'data-daily-scraiping-choka')
DEST_BUCKET = os.environ.get('DEST_BUCKET', 'fishing-catch-predictor')
FACILITY = os.environ.get('FACILITY', 'honmoku')
AWS_REGION = os.environ.get('AWS_REGION', 'ap-northeast-1')


def load_existing_fishing_data(s3_client, bucket: str, key: str = 'data/fishing_data.csv') -> pd.DataFrame:
    """
    æ—¢å­˜ã®fishing_data.csvã‚’èª­ã¿è¾¼ã‚€

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        key: S3ã‚­ãƒ¼

    Returns:
        DataFrame: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®DataFrameï¼‰
    """
    try:
        response = s3_client.get_object(Bucket=bucket, Key=key)
        df = pd.read_csv(io.BytesIO(response['Body'].read()))
        df['date'] = pd.to_datetime(df['date'])
        print(f"âœ“ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}è¡Œ (æœ€çµ‚æ—¥: {df['date'].max().date()})")
        return df
    except s3_client.exceptions.NoSuchKey:
        print("âš  fishing_data.csvãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        return pd.DataFrame(columns=['date', 'aji_count', 'visitors', 'water_temp', 'weather'])
    except Exception as e:
        print(f"âš  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        return pd.DataFrame(columns=['date', 'aji_count', 'visitors', 'water_temp', 'weather'])


def parse_daily_data(
    s3_client,
    bucket: str,
    facility: str,
    date_obj: datetime
) -> Optional[dict]:
    """
    æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ‘ãƒ¼ã‚¹

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        facility: æ–½è¨­åï¼ˆhonmoku/daikokuï¼‰
        date_obj: æ—¥ä»˜

    Returns:
        dict: ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆdate, aji_count, visitors, water_temp, weatherï¼‰
              ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯None
    """
    date_str = date_obj.strftime('%Y-%m-%d')
    base_prefix = f"data/{facility}/{date_str}"

    try:
        # head.csvã‚’èª­ã¿è¾¼ã¿
        head_key = f"{base_prefix}/head.csv"
        head_response = s3_client.get_object(Bucket=bucket, Key=head_key)
        head_df = pd.read_csv(io.BytesIO(head_response['Body'].read()))

        if len(head_df) == 0:
            print(f"  âš  {date_str}: head.csvã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None

        # å¤©æ°—ãƒ»æ°´æ¸©ãƒ»æ¥å ´è€…æ•°ã‚’å–å¾—
        row = head_df.iloc[0]
        weather = row.get('å¤©æ°—', None)
        water_temp_str = row.get('æ°´æ¸©', None)

        # æ¥å ´è€…æ•°ã¨å…¥å ´è€…æ•°ã®ä¸¡æ–¹ã«å¯¾å¿œ
        visitors_str = row.get('æ¥å ´è€…æ•°') if 'æ¥å ´è€…æ•°' in row.index else row.get('å…¥å ´è€…æ•°', None)

        # æ°´æ¸©ã‚’ãƒ‘ãƒ¼ã‚¹
        water_temp = None
        if pd.notna(water_temp_str):
            match = re.search(r'([\d.]+)', str(water_temp_str))
            if match:
                water_temp = float(match.group(1))

        # æ¥å ´è€…æ•°ã‚’ãƒ‘ãƒ¼ã‚¹
        visitors = None
        if pd.notna(visitors_str):
            match = re.search(r'(\d+)', str(visitors_str))
            if match:
                visitors = int(match.group(1))

        # body.csvã‚’èª­ã¿è¾¼ã¿
        body_key = f"{base_prefix}/body.csv"
        body_response = s3_client.get_object(Bucket=bucket, Key=body_key)
        body_df = pd.read_csv(io.BytesIO(body_response['Body'].read()))

        # ã‚¢ã‚¸ã®åˆè¨ˆã‚’å–å¾—
        aji_count = 0
        for _, fish_row in body_df.iterrows():
            fish_name = fish_row.get('é­š', None)
            if fish_name == 'ã‚¢ã‚¸':
                count_str = fish_row.get('åˆè¨ˆ', None)
                if pd.notna(count_str):
                    try:
                        aji_count = int(count_str)
                    except ValueError:
                        match = re.search(r'(\d+)', str(count_str))
                        if match:
                            aji_count = int(match.group(1))
                break

        return {
            'date': date_obj,
            'aji_count': aji_count,
            'visitors': visitors,
            'water_temp': water_temp,
            'weather': weather
        }

    except s3_client.exceptions.NoSuchKey:
        print(f"  âš  {date_str}: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return None
    except Exception as e:
        print(f"  âš  {date_str}: ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def update_fishing_data(
    s3_client,
    source_bucket: str,
    dest_bucket: str,
    facility: str,
    target_date: datetime = None
) -> Tuple[pd.DataFrame, int]:
    """
    fishing_data.csvã‚’å¢—åˆ†æ›´æ–°

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        source_bucket: ã‚½ãƒ¼ã‚¹ãƒã‚±ãƒƒãƒˆï¼ˆdata-daily-scraiping-chokaï¼‰
        dest_bucket: ä¿å­˜å…ˆãƒã‚±ãƒƒãƒˆï¼ˆfishing-catch-predictorï¼‰
        facility: æ–½è¨­å
        target_date: æ›´æ–°å¯¾è±¡æ—¥ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å‰æ—¥ï¼‰

    Returns:
        tuple: (æ›´æ–°å¾Œã®DataFrame, è¿½åŠ ã•ã‚ŒãŸè¡Œæ•°)
    """
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    df_existing = load_existing_fishing_data(s3_client, dest_bucket)

    # æ›´æ–°å¯¾è±¡æ—¥ã‚’æ±ºå®š
    if target_date is None:
        target_date = datetime.now().date() - timedelta(days=1)
    else:
        target_date = target_date.date()

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ã‚’ç¢ºèª
    if len(df_existing) > 0:
        last_date = df_existing['date'].max().date()

        # æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if target_date <= last_date:
            print(f"âš  {target_date}ã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ï¼ˆæœ€çµ‚æ—¥: {last_date}ï¼‰")
            return df_existing, 0

        print(f"ğŸ“… æ›´æ–°å¯¾è±¡: {last_date + timedelta(days=1)} ã€œ {target_date}")

        # æœ€çµ‚æ—¥ã®ç¿Œæ—¥ã‹ã‚‰å¯¾è±¡æ—¥ã¾ã§ã‚’æ›´æ–°
        current_date = last_date + timedelta(days=1)
    else:
        print(f"ğŸ“… æ–°è¦ä½œæˆ: {target_date}ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–‹å§‹")
        current_date = target_date

    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    new_data = []
    while current_date <= target_date:
        date_obj = datetime.combine(current_date, datetime.min.time())
        print(f"  å‡¦ç†ä¸­: {current_date}...")

        data_entry = parse_daily_data(s3_client, source_bucket, facility, date_obj)
        if data_entry is not None:
            new_data.append(data_entry)
            print(f"    âœ“ ã‚¢ã‚¸: {data_entry['aji_count']}åŒ¹, æ¥å ´è€…: {data_entry['visitors']}äºº")

        current_date += timedelta(days=1)

    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    if len(new_data) > 0:
        df_new = pd.DataFrame(new_data)
        df_updated = pd.concat([df_existing, df_new], ignore_index=True)
        df_updated = df_updated.sort_values('date').reset_index(drop=True)
        print(f"\nâœ“ {len(new_data)}è¡Œã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    else:
        df_updated = df_existing
        print("\nâš  è¿½åŠ ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    return df_updated, len(new_data)


def save_fishing_data(s3_client, bucket: str, df: pd.DataFrame, key: str = 'data/fishing_data.csv') -> None:
    """
    fishing_data.csvã‚’S3ã«ä¿å­˜

    Args:
        s3_client: boto3 S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bucket: S3ãƒã‚±ãƒƒãƒˆå
        df: ä¿å­˜ã™ã‚‹DataFrame
        key: S3ã‚­ãƒ¼
    """
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)

    s3_client.put_object(
        Bucket=bucket,
        Key=key,
        Body=csv_buffer.getvalue()
    )
    print(f"âœ“ S3ã«ä¿å­˜: s3://{bucket}/{key}")


def lambda_handler(event, context):
    """
    Lambdaé–¢æ•°ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

    Args:
        event: Lambda ã‚¤ãƒ™ãƒ³ãƒˆ
            - target_date (optional): æ›´æ–°å¯¾è±¡æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
              æŒ‡å®šã—ãªã„å ´åˆã¯å‰æ—¥ã‚’æ›´æ–°
        context: Lambda ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        dict: ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            - statusCode: HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰
            - body: JSONæ–‡å­—åˆ—
                - rows_added: è¿½åŠ ã•ã‚ŒãŸè¡Œæ•°
                - total_rows: åˆè¨ˆè¡Œæ•°
                - last_date: æœ€çµ‚æ—¥

    Example:
        # å‰æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        {}

        # ç‰¹å®šã®æ—¥ä»˜ã‚’æ›´æ–°
        {"target_date": "2025-11-13"}
    """
    try:
        print("=" * 80)
        print("fishing_data.csv å¢—åˆ†æ›´æ–°")
        print("=" * 80)

        # ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        target_date = None
        if event and 'target_date' in event:
            target_date = datetime.strptime(event['target_date'], '%Y-%m-%d')

        # S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        s3_client = boto3.client('s3', region_name=AWS_REGION)

        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        df_updated, rows_added = update_fishing_data(
            s3_client=s3_client,
            source_bucket=SOURCE_BUCKET,
            dest_bucket=DEST_BUCKET,
            facility=FACILITY,
            target_date=target_date
        )

        # S3ã«ä¿å­˜
        if rows_added > 0:
            save_fishing_data(s3_client, DEST_BUCKET, df_updated)

        # çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 80)
        print("âœ… æ›´æ–°å®Œäº†")
        print(f"  è¿½åŠ è¡Œæ•°: {rows_added}")
        print(f"  åˆè¨ˆè¡Œæ•°: {len(df_updated)}")
        if len(df_updated) > 0:
            print(f"  æœ€çµ‚æ—¥: {df_updated['date'].max().date()}")
        print("=" * 80)

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†',
                'rows_added': rows_added,
                'total_rows': len(df_updated),
                'last_date': df_updated['date'].max().strftime('%Y-%m-%d') if len(df_updated) > 0 else None
            }, ensure_ascii=False, indent=2)
        }

    except Exception as e:
        error_message = f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        print(f"ERROR: {error_message}")

        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': error_message
            }, ensure_ascii=False, indent=2)
        }


# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨
if __name__ == '__main__':
    test_event = {
        # 'target_date': '2025-11-13'  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    }
    test_context = {}

    response = lambda_handler(test_event, test_context)
    print(json.dumps(json.loads(response['body']), ensure_ascii=False, indent=2))
